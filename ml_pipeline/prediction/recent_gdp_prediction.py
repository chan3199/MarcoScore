import pandas as pd
import numpy as np
import tensorflow as tf
import joblib

# ğŸ“Œ ê²½ë¡œ
MODEL_PATH = "model/model_long.h5"
SCALE_PATH = "models/scaler.pkl"
DATA_PATH = "data/macro_data_scaled.csv"

# ğŸ“Œ íŒŒë¼ë¯¸í„°
SEQ_LENGTH = 24
drop_features = ["Consumer_Confidence", "CCI", "Initial_Jobless_Claims", "VIX", "USD_Index", "M2_Money_Supply"]

# ğŸ”§ ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜
def create_sequences(data, seq_length=24):
    X = []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
    return np.array(X)

# ğŸ“Œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv(DATA_PATH, parse_dates=["date"])
df = df[df["date"].dt.year >= 1980].reset_index(drop=True)
dates = df["date"]
# ëª¨ë¸ í•™ìŠµ ë‹¹ì‹œ ì‚¬ìš©í•œ drop ì»¬ëŸ¼ (ì˜ˆì‹œ)

# feature ì„¤ì •
feature_cols = df.columns.drop(["date", "GDP"] + drop_features)
X_all = create_sequences(df[feature_cols].values, SEQ_LENGTH)
last_sequence = X_all[-1:]
print("ğŸ“¦ ë§ˆì§€ë§‰ ì…ë ¥ ì‹œí€€ìŠ¤ shape:", last_sequence.shape)

# ğŸ“Œ ëª¨ë¸ & ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
model = tf.keras.models.load_model(MODEL_PATH)
scaler = joblib.load(SCALE_PATH)

# ğŸ“Œ ì˜ˆì¸¡
scaled_pred = model.predict(last_sequence).flatten()[0]

# ğŸ”„ ì—­ë³€í™˜ (GDPë§Œ)
gdp_index = list(df.columns).index("GDP") - 1  # date ì œê±°ë¡œ -1
gdp_min = scaler.data_min_[gdp_index]
gdp_max = scaler.data_max_[gdp_index]
predicted_gdp = scaled_pred * (gdp_max - gdp_min) + gdp_min

# ğŸ“… ì˜ˆì¸¡ ë‚ ì§œ ì¶”ë¡ : ë§ˆì§€ë§‰ ë‚ ì§œì˜ ë‹¤ìŒ ë¶„ê¸° ì‹œì‘ì¼
last_date = df["date"].iloc[-1]
next_quarter = pd.to_datetime(f"{last_date.year}-{(last_date.month-1)//3*3 + 4}-01") + pd.offsets.QuarterBegin()

# ğŸ“„ ì €ì¥
df_result = pd.DataFrame({
    "date": [next_quarter.strftime("%Y-%m-%d")],
    "predicted_gdp": [predicted_gdp]
})
df_result.to_csv("data/recent_gdp_prediction.csv", index=False)
print("âœ… recent_gdp_prediction.csv ì €ì¥ ì™„ë£Œ!")
print(df_result)
