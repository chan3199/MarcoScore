import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import joblib
import os

# ğŸ“Œ ê²½ë¡œ ì„¤ì •
DATA_PATH = "data/macro_data.csv"
SCALED_PATH = "data/macro_data_scaled.csv"
SCALER_PATH = "models/scaler.pkl"

# ğŸ”§ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_macro_data():
    # ğŸ“Œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    df = pd.read_csv(DATA_PATH, parse_dates=["date"])

    # ğŸ“Œ 1980ë…„ ì´í›„ ë°ì´í„° í•„í„°ë§
    df = df[df["date"].dt.year >= 1980]

    # ğŸ“Œ ê²°ì¸¡ì¹˜ ë³´ê°„ â†’ ì™„ì „ ì œê±°
    df = df.sort_values("date").reset_index(drop=True)
    df.interpolate(method="linear", inplace=True)
    df.dropna(inplace=True)

    # ğŸ“Œ ìŠ¤ì¼€ì¼ë§ ëŒ€ìƒ
    feature_cols = df.columns[df.columns != "date"]
    df[feature_cols] = df[feature_cols].astype(float)

    # ğŸ“Œ ìŠ¤ì¼€ì¼ë§
    scaler = MinMaxScaler()
    df_scaled = df.copy()
    df_scaled[feature_cols] = scaler.fit_transform(df[feature_cols])

    # ğŸ” NaN í™•ì¸
    if df_scaled[feature_cols].isnull().values.any():
        print("âŒ ìŠ¤ì¼€ì¼ë§ í›„ NaNì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
        print(df_scaled[feature_cols].isnull().sum())
        return

    # ğŸ“Œ ì €ì¥
    os.makedirs("models", exist_ok=True)
    df_scaled.to_csv(SCALED_PATH, index=False)
    joblib.dump(scaler, SCALER_PATH)

    print("âœ… ìŠ¤ì¼€ì¼ëœ GDP ë¶„í¬ í™•ì¸:")
    print(df_scaled["GDP"].describe())
    print("GDP ìƒ˜í”Œ:", df_scaled["GDP"].values[:20])
    print("âœ… ì „ì²˜ë¦¬ ë° ì €ì¥ ì™„ë£Œ!")

    return df_scaled

if __name__ == "__main__":
    preprocess_macro_data()
