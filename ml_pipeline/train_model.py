import pandas as pd
import numpy as np
import joblib
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler

# ğŸ“Œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ì‚¬ìš©)
data = pd.read_csv("data/macro_data_scaled.csv", parse_dates=["date"], index_col="date")

# ğŸ¯ ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜
def create_sequences(data, target, seq_length=24):  # ğŸ‘ˆ 12 â†’ 24ê°œì›”ë¡œ ì¦ê°€
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
        y.append(target[i + seq_length])
    return np.array(X), np.array(y)

# ğŸ¯ ì…ë ¥ ë° íƒ€ê²Ÿ ì„¤ì •
SEQ_LENGTH = 24  # ğŸ‘ˆ 12ê°œì›” â†’ 24ê°œì›”ë¡œ ë³€ê²½
X, y = create_sequences(data.values, data["GDP"].values, SEQ_LENGTH)

# ğŸ“Œ ë°ì´í„°ì…‹ ë¶„í•  (ì‹œê³„ì—´ ë°ì´í„°ì´ë¯€ë¡œ shuffle=False)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# ğŸ“Œ LSTM ëª¨ë¸ êµ¬ì¶• (ë ˆì´ì–´ ìˆ˜ ì¦ê°€ ë° í•™ìŠµë¥  ë³€ê²½)
print("ğŸ”§ Building LSTM model...")
model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(SEQ_LENGTH, X.shape[2])),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.2),
    
    tf.keras.layers.LSTM(64, return_sequences=True),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.2),

    tf.keras.layers.LSTM(32, return_sequences=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.2),
    
    tf.keras.layers.Dense(1)
])

# ğŸ“Œ Adam Optimizer ê°œì„  (í•™ìŠµë¥  ì¡°ì •)
optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)  # ğŸ‘ˆ 0.001 â†’ 0.002 ë¡œ ì¦ê°€
model.compile(optimizer=optimizer, loss="mse")

# ğŸ“Œ Early Stopping ì¶”ê°€
early_stopping = tf.keras.callbacks.EarlyStopping(monitor="val_loss", patience=20, restore_best_weights=True)

# ğŸ“Œ ëª¨ë¸ í•™ìŠµ
print("ğŸš€ Training model...")
history = model.fit(
    X_train, y_train,
    epochs=500, batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[early_stopping]
)

# ğŸ“Œ ëª¨ë¸ ì €ì¥
model.save("model/gdp_predictor.h5")
print("âœ… Model training complete!")


# ğŸ“Œ ì›ë˜ ë‹¨ìœ„ë¡œ ì—­ë³€í™˜ (ë°ì´í„° ë³µì›)
scaler = RobustScaler()
scaler.fit(X_train)
# ğŸ¯ ì˜ˆì¸¡ ìˆ˜í–‰
y_pred = model.predict(X_test)

# ğŸ¯ ì˜ˆì¸¡ê°’ì„ ì›ë˜ ë‹¨ìœ„(GDP ê°’)ë¡œ ë³€í™˜
y_pred_rescaled = scaler.inverse_transform(np.concatenate([np.zeros((y_pred.shape[0], data.shape[1] - 1)), y_pred], axis=1))[:, -1]

# ğŸ¯ ì €ì¥
np.save("data/y_test.npy", y_test)
np.save("data/y_pred.npy", y_pred_rescaled)  # âœ… ë³€í™˜ëœ ê°’ ì €ì¥

