import pandas as pd
import xgboost as xgb
import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
data = pd.read_csv("ml_pipeline/processed_macro_data.csv")

# íŠ¹ì§•(Feature)ê³¼ íƒ€ê²Ÿ ë³€ìˆ˜ ì •ì˜
features = ["Retail_Sales", "ISM_PMI", "Unemployment", "SP500"]
target = "log_GDP"

X = data[features]
y = data[target]

# í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# XGBoost ëª¨ë¸ í•™ìŠµ
model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=5)
model.fit(X_train, y_train)

# ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
print(f"ğŸ“‰ ëª¨ë¸ í‰ê°€ - MAE: {mae:.4f}")

# ëª¨ë¸ ì €ì¥
joblib.dump(model, "backend/models/gdp_model.pkl")
print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: `backend/models/gdp_model.pkl`")
