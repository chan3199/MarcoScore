import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf

# ğŸ“Œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
data = pd.read_csv("data/macro_data.csv", parse_dates=["date"], index_col="date")

# ğŸ“Œ ê²°ì¸¡ì¹˜ ë³´ê°„
print("ğŸ›  Filling missing values...")
data = data.interpolate(method="linear")

# ğŸ“Œ ë°ì´í„° ìŠ¤ì¼€ì¼ë§
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)
df_scaled = pd.DataFrame(data_scaled, columns=data.columns, index=data.index)

# ğŸ“Œ GDP íƒ€ê²Ÿ ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì°¾ê¸°
target_index = list(data.columns).index("GDP")

# ğŸ“Œ ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜
def create_sequences(data, target_index, seq_length=12):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length, target_index])  # GDP ë°ì´í„°ë§Œ ê°€ì ¸ì˜´
    return np.array(X), np.array(y)

# ğŸ¯ ì…ë ¥ ë° íƒ€ê²Ÿ ì„¤ì •
SEQ_LENGTH = 12  # 12ê°œì›” ë°ì´í„° ì‚¬ìš©
X, y = create_sequences(df_scaled.values, target_index, SEQ_LENGTH)

# ğŸ“Œ ë°ì´í„°ì…‹ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# ğŸ“Œ LSTM ëª¨ë¸ êµ¬ì¶•
print("ğŸ”§ Building LSTM model...")
model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(100, return_sequences=True, input_shape=(SEQ_LENGTH, X.shape[2])),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.LSTM(50, return_sequences=False),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1)
])

model.compile(optimizer='adam', loss='mse')

# ğŸ“Œ EarlyStopping & ReduceLROnPlateau ì¶”ê°€ (í•™ìŠµ ìµœì í™”)
early_stopping = tf.keras.callbacks.EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True)
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=5, min_lr=1e-5)

# ğŸ“Œ ëª¨ë¸ í•™ìŠµ
print("ğŸš€ Training model...")
history = model.fit(
    X_train, y_train, 
    epochs=50, 
    batch_size=16, 
    validation_data=(X_test, y_test),
    callbacks=[early_stopping, reduce_lr]  # ìµœì í™” ì½œë°± ì¶”ê°€
)

# ğŸ“Œ ëª¨ë¸ ì €ì¥
model.save("../model/gdp_predictor.h5")
print("âœ… Model training complete!")
